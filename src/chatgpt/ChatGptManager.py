import openai
import chatgpt.Contants as Contants

class ChatGptManager():

    def __init__(self, openai_token, model="gpt-3.5-turbo", temperature=.5, max_tokens_messages=300, max_token_summary=500):
        self.token = openai_token
        self.model = model
        self.temperature = temperature
        self.max_tokens_messages = max_tokens_messages
        self.max_tokens_summary = 500
        
    def get_chatgpt_response(self, messages):
        """
        Send messages to chatGpt and get answer back
        
        :messages: List of dictionaries describying a conversation, e.g. [
            {"role": "system", "content": "INITIAL PROMPT"},
            {"role": "assistant", "content": "hello message"},
            {"role": "user", "content": "Hello Assistan, I Have this problem"}
            ]
        :return: Subsequent message generated by ChatGPT for the conversation in input, e.g. "This is the solution for your problem
        :rtype: str
        """
        response = None
        
        try :
            response = openai.ChatCompletion.create(
                model= self.model,
                messages=messages,
                temperature=self.temperature,
                max_tokens=self.max_tokens_messages
            )
        except Exception as e :
            print("ERRORE OPENAI:")
            print(e)

        return response['choices'][0]['message']['content']

    def summarize(self, conversation):
        """
        This method takes as input a conversation transcript and generate a report based on the content
        
        :conversation: A String containing the entire conversation, e.g. ASSISTAN: questo è un messaggio USER: questa una risposta ASSISTANT: questa è una rispota. . .
                       Use the helper method get_conversation_transcript to create this input format
        :return: A summarization of the conversation based on requestes setted up into SUMMARY PROMPT constant
        :rtype: str
        """
        final_conversation = ' '.join(conversation)
        augmented_prompt = Contants.SUMMARY_PROMPT.format(final_conversation)
        summary = None
       
        try:
            summary = openai.Completion.create(
                model=self.model,
                prompt=augmented_prompt,
                temperatures=self.temperature,
                max_tokens=self.max_tokens_summary,
            )["choices"][0]["text"]
        
        except Exception as e :
            print("ERRORE OPENAI:")
            print(e)

        return summary
    
    def from_tuple_to_gpt_input(self, tuples, role_index, context_index):
        """
        Helper method to generate a list of dict from tuples.
        This method can be used to transform the result of a query on PostgreSQL into a input for ChatGPT
        
        :tuples: list of Tuples
        :role_index: index where to find the role in each tuple
        :context_index: index where to find the context in each tuple

        :return: list of dictionaries describying a conversation, e.g. [
            {"role": "system", "content": "INITIAL PROMPT"},
            {"role": "assistant", "content": "hello message"},
            {"role": "user", "content": "Hello Assistan, I Have this problem"}
            ]
        :rtype: list
        """
        list = []
        for t in tuples : 
            obj = {
                "role" : t[role_index],
                "content" : t[context_index]
            }
            list.append(obj)
            
        return list
    
    def generate_initial_message(self, name):
        """
        Helper method to generate a first message for system prompt of chatgpt.
        The method also setup a custom name for the user if INIT_CHATBOT_PROMPT is correctly initialize-
        
        :name: custom name for the user talking to the chatbot
        :return: list of dictionaries containing the first message of a conversation with chatGPT, e.g. [
            {"role": "system", "content": "INITIAL PROMPT SETTED UP"}
            ]
        :rtype: list
        """
        message = Contants.INIT_CHATBOT_PROMPT.format(name)
        messages=[{"role": "system", "content": message}]
        return messages

    def _get_message_transcript(self, message, role, username, botname):
        user_name = ""
        if role == "assistant": user_name = botname
        else: user_name = username
        message_text = f"{user_name}: {message}"

        return message_text

    def get_conversation_transcript(self, conversation, username, botname, role_index, context_index):
        """
        Helper method to generate a string containing an entire conversation, from a tuple input
        This can be used to create a correct input for the summerize function
        
        :conversation: list of tuples containing a conversation
        :username: the name of the user
        :botname: the name of the assistant
        :role_index: index where to find the role in each tuple
        :context_index: index where to find the context in each tuple

        :return: A string transcript of the conversation
        :rtype: str
        """
        transcript = "" 
        l = len(conversation) - 3

        for idx, message in enumerate(conversation):
            if(idx == 0 or idx > l):
                transcript = transcript + self._get_message_transcript(message[role_index], message[context_index], username, botname)
        
        return transcript